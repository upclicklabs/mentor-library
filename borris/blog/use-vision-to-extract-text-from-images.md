---
title: "Use vision to extract text from images"
source_url: "https://github.com/anthropics/anthropic-cookbook/blob/main/multimodal/how_to_transcribe_text.ipynb"
source_type: blog
mentor: "Borris"
date_synced: "2026-02-20T00:00:00Z"
---

# Use vision to extract text from images

This Jupyter notebook from the Anthropic Cookbook demonstrates how to use Claude's vision capabilities to transcribe and extract text from images.

**Note:** The full notebook content is hosted as an interactive Jupyter notebook on GitHub (3.54 MB). Visit the source URL to view the complete content with code examples, sample images, and outputs.

## Repository Location

- **Repository**: anthropics/anthropic-cookbook
- **File**: `multimodal/how_to_transcribe_text.ipynb`
- **Branch**: main
- **File Size**: 3.54 MB

## How to Access

1. **View on GitHub**: Visit the [source URL](https://github.com/anthropics/anthropic-cookbook/blob/main/multimodal/how_to_transcribe_text.ipynb) directly
2. **Clone the repository**:
   ```bash
   git clone https://github.com/anthropics/anthropic-cookbook.git
   cd anthropic-cookbook/multimodal
   ```
3. **Open in Jupyter**: Run locally with `jupyter notebook multimodal/how_to_transcribe_text.ipynb`

## Context

This notebook is part of Anthropic's Claude cookbook examples focused on multimodal capabilities, demonstrating how to use Claude's vision abilities to transcribe text from images. It is part of the broader multimodal directory that includes best practices for vision, reading charts and graphs, and other vision-related tasks.
