---
title: "AEO Playbook: How to Optimize for AI w/ Profound’s Josh Blyskal"
source_url: "https://youtu.be/GgGueQggcfU?si=OsF6lqBfrgksT8vO"
source_type: youtube
mentor: "Ethan"
date_synced: "2026-02-15T19:22:52.476922"
word_count: 10179
---

# AEO Playbook: How to Optimize for AI w/ Profound’s Josh Blyskal

[Music] Josh, I'm excited to have you here. Your company is taking the world by storm and this this whole AEO thing of course is as well or however you want to describe it which you may have some opinions on as well. But uh clearly I'm getting asked by our clients like daily seems like a new client is asking what LLM tracking platform should I

recommend. I uh you're not for everybody. You're an enterprise up market offering, but I've been recommending you a lot and it seems like demand is through the roof. Things are are wild over there and people are talking about profound like Yeah. How are things currently? It's it's been incredible right now. So I think just the last uh 2 days uh we've

just announced our series A so led by Cler Perkins Nvidia Ventures uh we've got you know Coastal Ventures jumping in there. It's been an incredible run right now. I think you know it's actually interesting. We've got clients across from you know small businesses all the way to enterprises and you know I think the moment for AI search in marketing is really starting to reach its momentum

and kind of really starting to find its rhythm. you know, marketers are really trying to do something. We're moving from that point where people are thinking, okay, this is a space to stay aware of all the way to the point where it's like, okay, as a business, we're seeing that marketers need to take action. Marketers want to know what's next. What are we going to do in search?

How do we get our traffic back? How do we think about these new systems and how they're going to influence things? I mean, uh, for context, you know, profound, we came out of stealth in August 2024, so we're fairly new in the in the world of software. um I guess relatively mature in the world of startups one could say but um it's it's been an interesting ride right like with

AI mode and you know the evolution of all these technologies as they continue to kind of evolve and we continue to track them you know the space has really started to find its its place and it's kind of its home within this wider search world so it's been really interesting it's been beautiful really yeah yeah a lot is happening all all at the same time we'll probably do another

podcast on this, but it almost seems it dovetales into the demand you're seeing is we're I think our whole industry is seeing this reporting need shift where we're thinking of like traffic's not the thing anymore. we need to be visibly showing other elements and of course a lot of what you all do is that uh but just as of this last week we were like making a more profound no pun intended

shift to highlighting chat GBT and our reporting and thinking about we got to like put traffic a little further down um in in the order of operations but clearly exciting times a lot uh can be definitely exciting for you maybe not a little nervous for a lot of SEOs But um still I think uh a positive change keeping us on our toes anyways. Yeah. I mean I think the search world

always evolves like SEO eats everything. There's like that that that little like you know there's like a there's like 10% of my of my heart that's like yeah I really want AEO to be really different than SEO. But I know like even if AO is different it's going to it's like as long as there's an engine that people are searching on that we need to optimize for it's going to get eaten.

it's going to be within that larger sphere. It just depends on what that like I always try to model it with like two different curves. there's like a curve of like adoption of like all right how many people are on these AI chat flows and then there's a curve of like difference right how different are the chat flows and so like right now the way I think that's like how I think about

the adoption to this whole market right like so let's just say adoption let's just pretend adoption is really low and it's not really interesting but the difference is huge that validates that the space is still worth kind of tracking and being in right like at least at a minimal level like okay if the difference is massive and maybe 5% of all searches are done through AI,

then you know at least those 5% of searches need to be understood because maybe they're super high intent or whatever. If you're in a situation where adoption is huge, but the difference is still low, obviously that's super valid as well. Like so if it's very close to Google search, but also 95% of searches happen on AI search, but it's not like exactly aligned. It's like we're in a

world where we still need to track it. Basically, I think the the takeaway is that like we're reaching a world where the adoption is getting higher with Google AI mode, all these different tools, and it's different. And that is like that's really the hair on fire problem that Profound is built to like solve. And that's what I do all day. I'm an AI strategist. So, I guide our

customers through basically all the different strategies, all the things that they need to do to actually tangibly improve and start to work on their AI visibility. And um that's what I'm excited to share today. I mean, it's going to be great. We're going to kind of get deep in there. I love talking shop. Nice. Yeah. I mean, you made me think of your one of the immediate

questions was um your new conversation explorer tool and there's those estimated search volumes in there. Can you share h what where first where those come from and to what you just said are there cleared I'm guessing you're also hinting at both how we optimize but maybe the type of searches are different but um are there differences is I mean there

are but yeah maybe just talk through some of that variation and also where you're getting that initial search volume data as well. Yeah, what I'll say is that the search volume data is really like we're really proud of that. We have a number we have some of the best data providers, some of the best data agreements um in the industry. We have the biggest um single database of

queries across these answer engines that exist outside of these model providers. And so we have this pipeline. It's just this beautiful pipeline that pipes in tens of millions of queries every single month across you know you know your chat Gvts your perplexities uh eventually Google a overview Microsoft co-pilot as we start to really think about how to scale this out but it's um it's

legitimate you know answer engine queries it's the first in the industry to have it uh so we you know no one's really built this before if you know if we were thinking about doing it again we'd probably have brought data scientists on you right at the founding. That way we could have been even earlier on this. Yeah. Because it's been uh it's been a huge value ad. Like you have you

have there's so many different platforms out there that do kind of what Profound does. But I think the advantage to what we're doing here is that we're we're we're going head first into the like into the mess. Like it's all the mud. Like it's like all right, how do we get the query data? How do we get the legitimate like actual information that people are searching for? Now that we're

able to model that, we're starting at this point where you can go in as a marketer and start to understand the key topics that people are actually asking about within your industry. So you could ask like, you know, how many people are asking about budget laptops versus, you know, gaming laptops or how many people are asking about, you know, corporate credit cards with lounge access versus

or Yeah, I guess. Yeah, sure. Corporate credit cards with lounge access versus corporate credit cards with employee spend management. You could see the differences there uh in real time. like it's a week-by-eek view which is incredible and so you know the way we got it it's in we've been working on it since November it's incredibly intense um you know we love our data partners

here's what I can tell you what I can tell you is that um there are basically two whole new intent groups that marketers are not watching out for like this is um this is definitely a breaking story we're working with our insights team right now to categorize and figure out how we talk about this insight but something like depending on the way you slice it something like 50% % of the

intent in the I mean and it it sounds kind of like duh obvious when you hear it but it's 50% of the intent in these answer engines is just like it's generative queries where it's just people like conversating and interacting with these models which means that yourformational type queries your navigational your transactional the commercial stuff all of that existing

stuff gets actually squeezed down into a much smaller proportion much smaller share when people are actually asking to do things I mean and it makes sense why like answer engines like what I can say is actually I can even give you the which this is really interesting I have this up right now this is our like visualization right here something like 40% of queries are just purely

generative there there's this new kind of area called no intent which is just people saying like yes please do that um go for it try again so it's this in it's this interesting world where like if you see the you know the SEO world is kind of in green over there in the bottom right hand corner and you've uh the AI search world kind of coming out pretty new. This is something that you know we

think is absolutely worth tracking because brands are going to be mentioned even if you're starting from a generative position. You know how do you position your brand to inherit a new type of query these new kind of these generative searches? What does chatbt actually use in its rag model when it's going to go find a generative piece of content like something like you know let

me edit a PDF. All right. So what pages are well positioned to win that particular piece if someone wants something that's you know obviously not chat GBT so long as chatbt does you know chat GBT image you know changed the game like you know canvas got a great like image creation plugin right now in chat GBT obviously you know midappril when chatgbt images came out maybe that

entire world shifted maybe other tools are going to be inside chat GBT in the same way or how do we make sure that our tools you know exist and continue like micro apps things like at even in a world where chat tptd is handling most of these generative queries, how do we position ourselves as like the next experience. So there's lots of interesting stuff. Yeah, go ahead. Yeah,

super interesting. So when you just to restate it back to you otherwise could be said go do something for me action like take an action is what generative means essentially. Yeah. It's like create um you know create me a spreadsheet of my employees hours you know create the schedule you know stuff like that but you know, if someone wants to do

something one step deeper, who's going to win that click? Who's going to win that search? Right? It it reflects what I think a lot of people are seeing, and I know Hrefs did a study on this as well. Uh like their their traffic, and I know it's true for us. We have like a contrast ratio tool. Tools are getting a huge amount of that volume. And I'm guessing that's where that's represented

a lot of the time. Is that fair to say? I think that's like a really good mode right now in AI search is thinking about how do we create experiences that are so specific and so high value that they overwhelm whatever basic level experience that chat GBT can create like thinking about micro apps thinking about micro experiences that's a really good way even in the traditional world of

starting to hedge your bets on the traffic side of things even if you don't want to even start thinking about AEO yeah it see I I know it's uh I I was talking to Kevin Indig about this as Well, it's like in traditional search, you're not really getting AI overviews on those kind of searches, too. So, it's like in some ways the most defensible and yeah, maybe it's actually much the

search volume is growing significantly because people are unlocking like, oh, I can do things and they don't this is a new mode of searching to your point that we haven't been thoughtful about previously. I mean, like the whole the whole search world is transitioning from like a means to an end to like the actual end itself. It's like, you know, when you were searching, you know, pre

LLM era, you know, the the reason you would search through all the blue links and you would look through all the information is to find the thing that you wanted to understand so you could go do a thing. Search is now just becoming all right, I want to do the thing. Let's just do the thing. Do it. Create it. Do it. Let's go. And so like it begs an important question about the shape of

websites to come. Like what's the incentive for top ofunnel? How do we think about top ofunnel? How do we, you know, how do we make that whole world work? At the same time, like I think it's still in all the AI model makers interest to try to keep those incentives alive as long as possible. I mean, without I mean, I think I think they all know that like training off of all this

content that's been kind of generously provided to them is the core to why they're able to disrupt traffic as much as they are. So, it's a really interesting world where, you know, human written highv value content, I think, is only going to get higher value and more scarce. Um, it's going to be kind of like finding, you know, a diamond in the rough eventually if incentives don't

change. Yeah, the business model, I mean, I I don't have access to Chachi's economics or any of the other LLMs, but it just doesn't seem sustainable unless they eventually go to a world of an advertising model of some sort, which you'd think would they would want to create some incentives to click out um to have that be an effective model. Same with Google, like they don't want to

lose that model. Well, obviously I don't want to get disrupted at the same time, but hopefully there's like some crossing happens where chatbt introduces that Google Oh, yeah. Re still can retain it and where you still have a open web that's fruitful. Yeah. With the with the ad model, I think I think that's the moment where the like ever so clearly once ads are supported within all these

AI search responses, magically, I think we'll start to see uh click-through rates start to improve and conversions start to improve as well. I just think the incentive is so it's so it's nasty but it's aligned against you know the people who have the website right now like the the trustworthiness of a chat GPT answer is so high people trust them like they're you know their Bible truths

same thing with to a lesser extent AI AI mode AI overviews um perplexity though Perplexity is doing a great job I think like if you're going to look at any model and look at maybe what's to come in the future perplexity is kind of the canary in the coal mine for this stuff cuz they were you know first to shoppability. They're doing sponsored queries now. So, you can go in as a

brand and you can sponsor those. You can sponsor follow-up queries. So, you write something like, I don't know, you know, what's the best non-perman what's the best non-permanent marker for my 7-year-old. Great. The next one's going to say, um, maybe the followup query is how to wash permanent marker off of walls, right? And then it's sponsored by like Clorox or something, right? Like

that's an interesting situation where you know as a brand you kind of want to beg the question like how do I know how do I track that? Like where's the search console for that? Where's the ad platform for that? What's that going to look like? Like what what's the how do I put money onto a keyword in AI search? Right? Right? Because if someone puts in a seven paragraph query, like, oh, I

have a, you know, there's I want to buy a car, but I've never bought a car before, and I really want to learn how to negotiate to buy a used car, and I like Honda, but the new Hyundai's look really cool to me. Also, I live in New Jersey. What car should I buy? What's the key word? Right? Like so I think there's also this world where at the same time as we're trying to kind of

understand what people are searching in AI models and what the searches look like and how to kind of group them up. We're hoping that the AI models actually meet us kind of halfway and start to try to build that understanding themselves and start to kind of build their own platform. It's a question I get all the time is like do you think profound is like cooked if if you know chatbt

releases a search console like actually to the contrary I think then we're in a much better position because then we start to actually have units of measure and and things that we can actually kind of latch on to to start saying all right that's you know that's a brick that's one unit all right cool we can plug this in and we can start to optimize for it it's the same way with like search

console yeah I perplexity in that four links at the top model I I don't know if it it it doesn't have nearly the demand of Google for any of us and there's no search console to my knowledge of like click-through rate. I'm curious what the clickthrough rate is on that. Do you have any sense of what that is for Perplexi? Is it quite bad from the from the four links at the top? Yeah. Yeah.

The interesting thing about Perplexity that we see from our own data is that Perplexity has like between like a six and 10x higher clickthrough rate than ChachiBT does for what it's worth. Uh even though perplexity has like a minuscule perplexity is the bing of AI search um if if chatbt is the Google of AI search perplexity is the thing but the conversions from perplexity are

excellent like um we'll see you know let's just say 10,000 views 10,000 you know visits from Perplexity out of you know 100,000 scrapes and we'll see you know million scrapes from chat tpt we can see this within answer I'm just making up fake numbers we'll see a million scrapes from chat tpt and we'll see you you know, 150,000 conversions from, you know, chat GPT. So, it's an

it's it's it's a really big difference across all these different models. I think the the quality of traffic is going to be really important factor though like I think the one bone that is kind of been thrown maybe unintentionally maybe I mean obviously kind of as a consequence of the space is the fact that like the traffic coming from these answer engines is extremely

high quality like they are ready to buy. They are qualified. So, when you get someone who clicks, a click is a conversion for the most. I mean, I've heard of traffic um CBR as high as 20 to 30% from ChatG. That's a high end. Like, I'm not going to say that's normal, but for sites where you can convert right on the site, you can sign up for a trial, you can demo, 20 to 30% um isn't

strange. And I've heard that more than five times, less than 10 times. Um but it's a pretty good sample size across maybe a few hundred customers who have asked the same question, too. Yeah, I mean our demand we hear it mentioned all the time that we we were found on recommended on chat GBT and perplexity. Uh I I think it's kind of interesting that some historical pessimism about

Google results and Bing results and like what a lot of like these best roundups would have like they're all paid and all those things and a lot of these models to my knowledge are using those exact same things but they're taking it as science when it comes through those. I wonder if that will persist. I I'm not sure. Maybe it'll just get better. Uh I don't think so. I I don't

think we're in a world where anything here is solid ground. I think everything this is like quicksand bill basically. Um yeah, listicles comparative content. We have I have a data data set of like 177 million citations that I use here internally at Profound. It's like the it's like the king data set of everything. Um listical comparative content are 32.9% of all citations.

That's the number one most cited single type of content. The number the number two is blog all blogs and opinion at 9.9%. So that gap is humongous right now within AI search. Yeah, I remember seeing I think it was a uh man I should just we just we off top of my head but it was like research affiliate products are getting sourced a lot but blog

content was like actually very low like 1%. I guess I is that it sounds like you still have a little higher than that in your numbers. Um yeah, but curious if you've seen that study X maybe it's XFunnel. I think it's accurate. I think like directionally they're accurate. I think you know it depends how you slice everything up. I mean you know they could get 1% but if they're if the basic

finding is that like listical affiliate content's winning and blogs are kind of a a sad number too. Yeah, it's true. Yeah, this is great. Xfunnel. Oh yeah, I guess I do see blog here at 9%. So that's basically what you're saying. Maybe I was misrepresenting that. That means my data pull is pretty good. Um yeah, I brought that up. That was uh that's my old like Brighton stat. But um

yeah, I mean the situation here with that is that like right now the answer engines are predominantly still using we're still kind of most searchers are still using those 40 models. They're not doing the deep research as long as we're on that like one search and done kind of methodology. And AI mode's challenging that like I'll I want to like put that off to the side. We'll talk about AI

mode, but like as long as we're on those forum type models when they have to do one or two searches, they're always going to bias towards the listical to try to get the widest breath like kind of like the marketplace of answers. So if I ask an answer, best men's running shoes, right? it gets to throw one, you know, chatp gets one query over to the Bing API, maybe two queries over to the

Bing API. It's it's going to be limited in what it's going to be able to pull and it's going to want to try to find someone's article that lists everything about the industry out, all the top players. It's going to grab those top results and then it's going to throw those back into the user and be like, "All right, yeah, the top list, the top uh men's running shoes are 1, two,

three." You'll go to the listicles that it sources and it's like, "Yeah, no surprise. It's number one, two, and three in the listicle as well." um like it it's that like marketplace that everything's being forced kind of like into basically. I'd say like right now answer engines want to make a marketplace with deep research 03 and the query fanning and AI mode. I think

those things are going to change. I think we're in for a big change there because those answer engines actually have the time to go visit the product pages and go visit the review sites and go see every individual page. Fingers crossed hopefully. Um because I want them to be able to come up with their own opinions. like if I I basically personally stopped using um like 04 with

search on cuz I was like I don't want to read you know the summary of I want to just like you know go through a deep research if I'm buying anything like serious serious it's at least what I do um because I mean it's it's right now we're in a very transitory stage like we've got this rag model with open AI it's heavily reliant on Bing like for anyone who's listening who doesn't know

already um Bing is the foundation of chat GBT's retrievalss Right. So if your site's going to appear in chat GPT, it has to get indexed in Bing and then chat GPT2 will index it in its own index. But if you're not in Bing, you're not going to make it through that first filter. But this rag methodology that's using Bing is it's it's really kind of made by academics. Like you've got a bunch of

PhDs in the room. They want to make a performance system. They're not thinking about marketers or SEOs or AEOs or whatever to call this space. um they're thinking about how to like how to scale something that gets web pages that are reasonably accurate in a reasonable amount of time that provides value to the user. Um I think that's going to shift that whole thinking over

at OpenAI as long as they want to continue being a pretty serious search engine right now is going to have to it's going to have to shift pretty seriously in time to start thinking about people who are going to be optimizing for these systems. A great case study right now is like looking at you know those listic goals like that's um I don't think that's that can't be

permanent right because then every brand is just going to release you know a top 10 comparative listical as with any SEO strategy it's in vogue for like a year and then it's done. Yeah, I mean they they work uh unfortunately. Um so we'll keep doing them while they do. But I mean do you think the pricing uh I mean I'm no tech expert. I know generally things

tend to exponent or get very a lot cheaper over time and I know they already have already. Will that I know the fan out mode of AI mode um for Google does some of that. Um, do do you think this will be something that'll be accessible? Just my mom. Oh, like deep research and stuff like that. Yeah. Just on a like a consistent basis. Yeah. I mean, it kind of has to be. I mean,

here's my here's my real thought. Um, I think I think in the future I think LLMs are going to get dumber. I think that's my like take that I always tell people is that we've got this we like we're in this awkward space with LLMs where they're doing this job that they're not supposed to be doing which is like if I ask an LLM who the count of Dusseldorf was in 1443 it's going to like

reasonably try to tell me that information. That's not the LLM's job. The LLM's job is to model the the language. It's just its job is to be the interface that I can understand. And in an optimal world, I would have a very small, very optimized LM that's like super good at modeling language and then it would be connected to a really smart brain that lives somewhere else that

does all the knowledge stuff for it. So like I like if you're trying to use like chat GPT on your iPhone, if anyone like downloaded that like chat GPT extension um when Apple intelligence first came out, people like oh you can use chat GPT on the iPhone. You can ask hey chat GPT search this. It's just doing an API call. My future vision of this is that you'll be able to run hopefully an LLM

on your phone locally and that LLM is going to be relatively robust. It'll connect like a Google search or a series. Like I can't believe Siri is not incredible yet. Um because they've got all the different techn all the pieces. They just Apple has to build it in house. But they'll run a query. That query will do deep research. That deep research piece will be handled by some

sort of intelligent engine, some sort of search engine piece. Then the LLM, the answer engine, whatever. call it what you will is going to actually go in and write that answer to the user and that's the piece it's like that that user relationship piece is really where the LLM starts to really own and the knowledge kind of gets offshored as far as I feel with like pricing and things

like that Google is just like I mean Google is just driving towards turning queries and compute into a commodity in the space like Google's like yeah you want to charge for tokens open AI how about free how about just free search 50 searches 80 websites how about you pay nothing. Um, that's hard to beat. That's just a hard economic problem for anybody else, which is I mean, it's a great

business move, right? It's exactly what I would do if I was Google. Yeah. Reminds me of the Amazon model that made them so uh efficient that they just crushed everybody because they could lose money on certain categories until they won a category because they had Google. Google has the search ecosystem to do so much of that. I forget who it is. There's like there's even like this

research group right now hiring with there's like a research group in the AI space. It might be Meta. I think it's Meta. The signing bonus for the top research talent in the world right now is $100 million uh per person with it's 75% stock but 25% liquid which is crazy. Yeah. Yeah. I saw they were trying to recruit uh people from Open AI. It's pretty wild story. We'll add that to the

show notes. But, uh, you're sort of maybe you're touching on I don't even know if you're recommending those listicals of clients, but like thinking about this dichotomy and of AEO to SEO or SEO for AI or however you want to call it, but like doing optimization for these tools compared to search. What do you think a strategy right now is, if there are any that you would do for

specifically LLM benefit that you wouldn't do or maybe you wouldn't prioritize the same way? um to make it helpful for people. I think there's there's some really interesting stuff right now with like stuff I wouldn't do with SEO that that that makes it really difficult because the way I like to contextualize the relationship between AEO and SEO is like like here in AEO

land we are still working out the same muscles like we are using metad descriptions title tags schema um you know FAQs we're using we're still writing for featured snippets but maybe albeit with a little more databased um insight from what LM are doing. We're still thinking about our URL slugs. We're still thinking about eat and content, but we're doing all of those

things. And the way I say it is like we're doing slightly different exercises, but for the same muscle groups. And so we're basically thinking about how to use those same units in a different way. So there's a few things that I would I'm going to I'm going to lead with like kind of this is the ultimate optimizer mode thing. Like if you're a crazy optimizer and you don't

even care about SEO, you want you're like let it all burn. I want to just be visible in answer engines. This is one thing you can do immediately. But I think it's it's it's not best practice in SEO because of redirects. I think you might know what I'm I might some of you might know what I'm going to say, which is that you can put 2025 in your URL slugs in your title tags and in your

metad descriptions and see an upwards of 20% improvement in chat GPT citations just by the inclusion of 2025. And for everyone asking why, the reason is because chatgbt appends 2025 to the end of search queries it sends off to the Bing API. So you you say something like I want to buy that new car blah blah blah all that other stuff you said and then JGBT reads that seven paragraphs.

It does something it basically calls regularizing the query. So it basically turns it into the query that it decides it's going to send to Bing. So it asks um you know best used cars, best used car dealerships uh New Jersey 2025. Appending 2025 instills a bias in both the Bing API obviously and in Chad GPT's model to basically pick and drive towards resources that just so happen to

include that string 2025 in the end results. Like that's why I say this is the ultimate optimizers play because you're going to be dealing with redirects in 2026. What are you going to do? What's the plan for any of those things? Like do you create the 2026 page? It's kind of awkward, but we've seen customers who are saying, you know what, I'm going all in on AI search. I'm

just going to do this. I'm going to try this. The pickup is insane. Um there's some great research right now as well on LinkedIn pulse like building consensus right now in models. So people are saying, you know, if we're going to create a blog post, it really does help to cross-ost that into LinkedIn pulse so that when chatbt does search or, you know, your perplexity, your AI mode does

search, it sees a few different sources saying the same thing. You know, maybe your blog, maybe over at uh LinkedIn saying the same thing. And then we can go as the model and feel pretty confident that, okay, multiple sources are saying this, this is something that's known in the world. Got it. I'm going to show this to the user. There's a few more. I'm I'm going to hit on

maybe two more. I think semantic chunking is a really big win. Semantic chunking with data to be very specific. So, what does that mean? What that basically means is that when we're writing our blog posts, when we're writing for answer engine pickup, what we don't want to do is we don't want to we don't want to create paragraphs or or areas of our content where the exact

meaning or maybe the exact insight from that piece of, you know, writing, that paragraph is kind of muddied. We want to keep insights really snappy, really databased, really data driven. And we want to almost think like thinking back to how chatbt answers our questions. Can I format an answer as kind of a self-contained paragraph within my within my content? Exactly. Cuz when

Perplexity wants to go and look through its vector database of all the searches, when JTBt wants to understand in its index what source to site, it's looking for hyperspecific answers to longtail queries. And so building those hyperspecific answers is really really important. It's really powerful being the person who takes data from you know all the best listicles in one space and

creating like the master like crazy listical with like you know your competitor has seven different dimensions you have you know three and then your other competitor has seven more. You grab seven dimen the seven dimensions they're comparing the seven dimensions from the other competitor and then add two more on top just for good measure and then create like a killer

structured table in HTML for answer engine pickup. you're going to see citations just as a natural result. Like the answer engine you you want to create the best marketplace, the best the best venue for a lazy, tired answer engine to come and be like, "All right, great. Finally, the place to learn everything about men's running shoes. Cool. I'll just Thank you so much, uh, Ross. I'll

just take your answer and I'm just going to go show this to the user. Cool." Takes it, steals it, throws it to the user. That's the I mean, that's the name of the game. Uh, for those are great insight zones. One of the things I've been personally curious about is like do you think there's actually a very clear uplift to implement schema.org on like I think you

describe the semantic chunking like it maybe it's like a FAQ list at the bottom of a blog post or something. Um is that notable? I I was just chat GPT and googling if I is there any actual data that supports this rather than just like structuring the article well curious your thoughts on that. I have experiential like I have experiential data with it. We refactored a few

websites with customers. Um the thing with doing that kind of stuff if like if I'm working with someone who doesn't have schema and um schema markup I'm also probably changing a bunch of other stuff on the site. Like I'm going to be very honest like there's also a bunch of other things I'm probably going to be doing on the site at the same time. Um I don't have a rigorous study into schema.

I think the best uplift I've seen so far surprisingly is author schema which is really weird. like really building out like a nice author schema has been really nice for answer engine pickup. Um that one I'm still that's like that's a 2 or 3 week old insight. I'm still trying to dig into it in my spare time why that is. But we were working with a cyber security company. Uh they had a

few cyber sec experts commenting you know writing some guest blogs. We just built out a little more author schema just really kind of started to standardize the way that that was going to be placed on the site. and um answer your pickup increased drastically from existing pieces of content. So that was interesting. I think the biggest thing right now is there's two kind of areas

that I would really start to think about. I would think about your URL slugs, semantic long descriptive URL slugs win an AI search. That is clear to us at least like the the data is overwhelming in that regard. So, if you have a a page that's like, you know, um Ross.com/c corporate credit cards and it's a listical that's comparing the best

corporate credit cards, that /corporate credit cards URL alone, just assuming the same content across both pages is going to lose every time to some like total nerd who's looked at the data and can see that you should be writing for answer engine pickup best- corporate-credits- compare 2025. in the URL slug. Even without the 2025,

the performance uplift is um a pretty significant magnitude. I would say it's probably between like 3 to 7% citations just from a really nice URL slug. Because when these answer engines, especially Chat GPT, looks at those Bing API results, it is trained specifically to look at URLs and look at results that it's highly confident in. It is supposed to only click on things that it believes

contains after the click the exact answer it needs. So, if it's looking at 10 pages that say corporate cards, corporate cards, corporate cards, best corporate cards compared. Don't mind if I do. Click. Uh, same thing with metad descriptions. It can see the metad description. So, in a lot of ways, when you're thinking about being cited for answer engines, it's

kind of a twostep game. So, step one is like kind of marketing the cover of the book. It's like, all right, we want our URL slug to look really good. We want our metad description to be really sexy so that the answer engine thinks that there's a lot of value behind the page. And then when we click on that page, we want that page to be presented in a structured detailed way so that the

answer engine's click is not wasted. It gets the information it needs. We actually do influence the search and then that information is brought forward to the user. Makes sense. What uh some like follow-up questions there. One thing I've been that's been top of mind for me in this direction is when you do a lot of these articles on site, you end up with 2025

and like all of your your titles and it looks spammy because you have like nine related links. They all say 2025. Guidance to the team has been just kind of indicate this in the title tag, not have it in the post level, the post title. And generally because we are going more evergreen, don't want to redirect URLs. We we wouldn't have a year in the URL. But you're specifically

calling out the URL a lot there. Do you think I I'm guessing this is just like classic being optimization is just like not as good as Google. Um but any thought on the title tag versus URL? I think the title tag is like the title tag is the normal person path to do this. Um, if you're crazy, the the crazies are doing the URL just because if you're going for broke, it is the

area where very few people are still touching. Like it's it's the blue ocean for this kind of thing. I think everyone the basically the moat to putting 2025 in your title tag is just so much less significant than putting it in your URL. You're like full sending it. If you're going to put it in the URL, you're you're really buying in that this is going to be this one thing. Um, I would

say the title tag for 90% of people is going to be just fine and an excellent choice. I think there's like this subset of like ultra optimizers who are just like like we work with customers who don't care about SEO anymore, frankly. Like they're just like, "Okay, or even like they haven't started. They've never done SEO before. Like new companies, fresh like I don't even really worry

about SEO. We're in an industry with massive incumbents. I don't care. I don't really want to fight against, you know, building this content out." The interesting thing is like they say they want to only do AEO. In reality, they're doing both at the same time with a little AEO kind of sprinkle on top obviously, but the name of the game is just like just thinking about how to

make things super obvious for these answer engines. We I mean internally or profoundly call that uh agent experience. It's like it's kind of everything, right? It's the it's the operator being able to go on your site and click around, you know, seeing all the different menus, making your menus understandable. It's your LLMs.txt, LMS.ext, whatever people call it these

days. Um, that uplift, people are so skeptical of that. I think to set I I always want to set the record for that because there was this moment I think in March, April, where everyone was like bullish. We're all going to try it. We tried it. Didn't change that much about our referral traffic. It didn't change that much about our crawl rates if we looked at our network logs. I think

that's an accuracy play. Like I think LMS.ext text is really a play where we're trying to make sure if you know if a developer is using cursor or if someone's asking about the relationship between our products that that information is portrayed appropriately. I also think like if we're talking about LM text if I'm going to be really quick here explicitly allowing LMS.ext in your

robots.txt txt even if it's you know totally redundant it's like absolutely redundant to do that but we've seen it drastically increase the amount of actual pickup from answer engines like RL gets picked up yeah quite significantly because of that um also there's this thing called LM's full text if you're a software that has a lot of documentation the play with LM's full

text and we work with a few really really um you know smart teams who have done some good research into this Even beyond what we've done, they found that you go to your docs page. So like imagine tripfound.com/doccks, then you would do /alllms-full.ext. It would be a markdown file of all of your documentation hosted there. We see that getting picked up something like 5

to 10x more often than your standard LMS.ext because of those the specifically cursor um and windsurf. Okay. Interesting. Yeah, I know there's been some some people just saying there's like it almost what's a comparable example I think of AMP. I don't know if it's the best example of like no one's actually adopting it. Like do you think it's going to matter long

term? Is this going to continue to be something? Yeah, I think it has to matter long term. That's the interesting thing about this. It's like for going to this world where the answer engines are arbitrating true versus false or what products matter. We've got to create I think there's going to be a basically a two-tier highway. We've got to create a way for these answer engines to access

information consistently in a in a standard way across our sites that doesn't rely on the old paradigm because you know I think temporarily at least JavaScript isn't rendered temporarily at least there's some blockers with crawability. People are still restricting answer engines from being able to see certain pieces of content. Rightly so for some brands, some

companies, no shade there. I think it's a great play. It's important for some folks, but I think there's also a world where we want to make sure that that maybe second layer of the freeway is still open and clear so the answer engines can go get that information. Like in my perspective on the future of search, I have a pretty optimistic one is that answer engines allow us to

really free the website up to be a really exciting maybe unoptimized place. Like maybe the userfacing.com website is actually like radically designed and is not super intuitive for answer engines and it's almost like kind of like an a piece of art rather than an actual like because websites right now to to my opinion look very sy right now. Websites are very optimized. There's a very

similar structure in in kind of a basic sense across websites allowing answer engines to confidently go in and navigate some sort of backend architecture be it LLM.ext text be it whatever it is allows us to do crazy things again with our websites. I want to see weird websites again like I want to go back to the you know early days of the internet and see those like archive

sites. Yeah. Right. So I think you know there's there's there's plenty of different areas where things can go. Um but I think that that avenue more than anything else I like where websites aside that avenue still has to be clear. We have to decide, you know, how do Answer engines access pages? And I think just kind of like shrugging and saying, "Well, they'll just do it the same

normal way," is kind of a lazy answer. I think that, you know, creating a markdown file is not the craziest thing for brands to want to do. Yeah, makes sense. One one follow-up question on the time freshness, have you seen just from a lift on just time stamp, so it's like the post date on the article? Yeah, that's that's pretty massive as well. Huge. Huge. Yeah, humongous. There's a

decay in almost all content in answer engines unless it's like it's your first week on you know on publishing is great. You'll we see content get picked up in the scale of like two one two three days. You you'll release a piece of content. It'll get cited. It'll be 2% of the truth of like a multi-billion dollar industry. Like it'll be like you'll like I don't know Chase Bank will release a

piece of content two days later it'll account for 2% of all citations in the industry and then it'll start kind of dwindling and dwindling for the next month until it reaches like.5% which is really where it's at for the next like 3 years. Do you think that's the decay cycle is one month? I think the decay cycle is anywhere from like a month to two months in my experience. Yeah, it

really does take like a month or two to really find your like your actual area. The interesting thing is that those timestamps um they're dependent on the size of the industry, right? Like if you're writing about feather caps uh in Texas, you're going to be fine for the most part because you're going to be the only person doing that. But if you're talking about something like I don't

know um what's a great one? CRM. Talking about I came from HubSpot's uh SEO team. Shout out to HubSpot. But um if you're talking about CRM, you're going to be covered up by some rando writing another article, you know, the next week, especially if everyone knows that listicals are the way to do it, right? Um content quality is going to sorry, content quality is just going to have to

get really important soon. I we have a general stance like it's about relative freshness on that search result. When we're thinking Google of like you if it is a query like best CRM software often that can be a quart like everything's a quarter or less old for something like best credit cards is actually can be under a month. Uh best headphones could be like one week I

think. Yeah. I would guess it would be very similar like it's probably using those similar results to inform. But do you think there's any variation? I mean clearly it's going more exacting and but is it even more prof profound um in that way? Yeah. I mean everything is kind of accelerated right now in AI search is what I'd say basically on the on like the on the data set like things go up

things go down much quicker. If you're seeing things on a week with headphones and traditional search I'd say that that sounds perfectly accurate to what I'm seeing within AI search as well like things like you know industries where things are just always moving. The way to stay defensive there is commercial landing pages just because I mean there's always going to be and weirdly

enough Wikipedia that's like a side thing. Wikipedia, let me uh let me just append that. Wikipedia commercial landing pages um and Reddit are like really some of the strongest um evergreens right now in AI search just to be very clear because those specific resources are kind of like totem poles for these answer engines. They just they ping them out of

necessity. they feel that that is an important place to check the box at. They will hit a certain Reddit thread. Um they will hit the Wikipedia page. Wikipedia page is super underrated. The problem with Wikipedia is just like you can't really it is what it is. I I really I am not I don't get into the Wikipedia world. Uh I just it's it's like if you want to I the only as far I

go as far as saying you should create a Wikipedia page if you don't have one. But I I don't think that there's any real structural way to think about optimizing. I mean, I'm sure someone's out there someone out there is like listening is like tearing their hair out. They're like, "Yes, there's a structural way." I'm sure, but I I I can't even get into it with Wikipedia.

It's just so difficult to really break through and do that consistently and like create a structure by doing that. And I mean, they'll kill you. They'll kill you. Yeah. And that's that's their job. Like, rightly so. I don't want I don't want Wikipedia to be a marketing channel. Um, it just so happens the answer is pull that way. So, I think that's also just an interesting piece.

If I'm reading between the lines of some of the things you said, like it sounds like you from a futurep proofing standpoint, you're recommending developing real longtail commercial landing pages. Yeah. On like eventually the deep research models may go that direction. Is that sort of what I'm hearing? That feels like a C. Maybe that's newer where previously you may

have just done a longtail blog post rounding up the best options and putting yourself first or something like in the in the ideal world right now. If you're thinking like how do we win for the next year or two? Right now it's about creating a landing page for any kind of like it's almost like problem oriented. It's like a solutionoriented landing page like like map every use case to a

landing page for the same product almost. And it sounds insane, but it's exactly right. Like longtail CLPS are a great evergreen way to stay ahead because there's always going to be that moment where the answer engine just needs to at the baseline know which solutions exist in the industry. Like if you're thinking about I let me just think about it like I don't know um no

zero trust proofs. I'm just making this up. Let's just say some company is out here creating zero trust proofs which is like it's a crypto thing. Um, you know, you would just create like joshcrypto.com/zerrust proofs. When people ask about zero trust proofs, you would your page would show up because it's one of maybe five. There's Ross Crypto, Joshcrypto, and

Bobcrypto.com. They all have their zero trust proofs pages, right? And the enter engine's going to hit each one of them. It's kind of like that. And you can go longer tail. I mean, you can go crazy, right? I mean, it's it's as deep as your products go. Yeah, makes sense. And there's ways to have that be user friendly where you have like a all use cases

site mapage type thing that goes off the core. I've seen that be effective. Well, I feel like I could go like an hour and a half with you, Josh, but I want to make sure uh be respectful of your time. Any other like research or product launches or anything else that's upcoming that you're excited? We already talked about some of it. Um, but anything else that we should chat about?

I mean, we are I mean, we're excited to tease basically what will be coming in the next few months, which is our our actual actions piece of the platform here at Profound. So right now some of the biggest feedback we get from uh marketers and users alike is that this data is incredible. the data is you know worldclass leading you know no one has this data but how do we actually

understand how do we understand for our site for our brand how to actually take action um one of the things that we're building right now maybe I can even search it up maybe not but um I'm not even I'm not going to do it right now but one of the things we're building right now is this ability to actually create content briefs and create content within the profound platform itself so

no longer are you going to have to go out to an external source or use a chat Deep research. We're going to be able to use this massive hundreds of millions of rows of data, huge data sets to create real actionable AEO optimized content direct for your brand, which is going to be insane. I think you know driving towards the future. The future is basically, you know, autonomously

starting to think about what the solution is for your brand, for your for your industry, for your company, and then bringing that directly to you. Like maybe in the future there's not going to be a need. hopefully for that much AI strategy. Maybe that's all going to be visible in the data. Maybe I can go do something like maybe I'll go be a fisherman in Bosnia or something. I

don't know. But it'll it'll be an interesting evolution in the space, I think. Uh and I think it's going to really um I think it's going to redefine like what it means to start kind of optimizing because it's just it's pure databased optimization, learning from the best patterns in the data across this massive data set. everyone's going to have the ability to really go in

there and start thinking like a top tier researcher who's got all this data like just thinking about all these different factors. So, it's going to be very cool. I'm excited about it. Nice. I I'll look forward to checking that out. And I know you Yeah. have historically been a I mean, you're up market, but you have a self-s serve option now that's 500 a month at the time of this Yes.

recording. Yeah. Yeah. It's more more accessible. So, that's great. Um Yeah. You're putting out some great research. Uh yeah, you putting some good stuff out on LinkedIn. Any anything else? How should people find you? Oh man. Yeah, find me find me on I mean, yeah, Josh on LinkedIn, find us on Tribeound, find us on ChatGpt, Perplexity. Um yeah, I mean, yeah, sign up, check it out, email us.

Um we are really interested to show you what's going on with an AEO, what's going on with your brand. Um yeah, it's really interesting space. Appreciate it. Awesome. Thanks for coming, Ross. Absolutely. [Music] Hey, [Music]
